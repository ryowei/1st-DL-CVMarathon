{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day015_Cifar_HW.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKJC6LseM3KI",
        "colab_type": "text"
      },
      "source": [
        "## 『本次練習內容』\n",
        "#### 運用這幾天所學觀念搭建一個CNN分類器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkAymc_ZM3KO",
        "colab_type": "text"
      },
      "source": [
        "## 『本次練習目的』\n",
        "  #### 熟悉CNN分類器搭建步驟與原理\n",
        "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK1aYGPxM3KP",
        "colab_type": "code",
        "colab": {},
        "outputId": "41997ab3-6146-4d08-fe48-55bb4b1ea0ab"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTR83Ww9M3KY",
        "colab_type": "code",
        "colab": {},
        "outputId": "269729cd-d3e9-4a93-d7b0-4ec37667452c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape) #(50000, 32, 32, 3)\n",
        "\n",
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7) \n",
        "        return X_train, X_test,mean,std\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdJQKc_9M3Kd",
        "colab_type": "code",
        "colab": {},
        "outputId": "637be739-7019-4e72-e76e-2bf1c76c464b"
      },
      "source": [
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(y_train).toarray()\n",
        "y_test=one_hot.transform(y_test).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqneALQPM3Ki",
        "colab_type": "code",
        "colab": {},
        "outputId": "763e8acb-b41c-426e-89a9-bd6766d8b53f"
      },
      "source": [
        "classifier=Sequential()\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(input_shape=(32, 32, 3), kernel_size=(3,3), filters=32, activation='relu', padding='same'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(kernel_size=(3,3), filters=32, activation='relu', padding='same'))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "#flatten\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#FC\n",
        "classifier.add(Dense(output_dim=100, activation='relu')) #output_dim=100,activation=relu\n",
        "\n",
        "#輸出\n",
        "classifier.add(Dense(output_dim=10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#超過兩個就要選categorical_crossentrophy\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1217 15:15:20.593189 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1217 15:15:20.622310 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1217 15:15:20.628475 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1217 15:15:20.689551 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W1217 15:15:20.690587 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1217 15:15:20.729074 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W1217 15:15:20.895894 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
            "/Users/chibaryowei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
            "W1217 15:15:20.952224 4624973248 deprecation_wrapper.py:119] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W1217 15:15:21.087893 4624973248 deprecation.py:323] From /Users/chibaryowei/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 178s 4ms/step - loss: 1.3869 - acc: 0.5132\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 168s 3ms/step - loss: 0.9571 - acc: 0.6626\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 166s 3ms/step - loss: 0.7740 - acc: 0.7269\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 168s 3ms/step - loss: 0.6348 - acc: 0.7758\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 158s 3ms/step - loss: 0.5040 - acc: 0.8236\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 159s 3ms/step - loss: 0.3871 - acc: 0.8640\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 183s 4ms/step - loss: 0.2877 - acc: 0.9006\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.2132 - acc: 0.9259\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 193s 4ms/step - loss: 0.1568 - acc: 0.9457\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 158s 3ms/step - loss: 0.1442 - acc: 0.9498\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 160s 3ms/step - loss: 0.1256 - acc: 0.9561\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 166s 3ms/step - loss: 0.0998 - acc: 0.9648\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 165s 3ms/step - loss: 0.0806 - acc: 0.9727\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 216s 4ms/step - loss: 0.0804 - acc: 0.9732\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 942s 19ms/step - loss: 0.0772 - acc: 0.9736\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 168s 3ms/step - loss: 0.0710 - acc: 0.9755\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 181s 4ms/step - loss: 0.0639 - acc: 0.9778\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.0653 - acc: 0.9786\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 184s 4ms/step - loss: 0.0584 - acc: 0.9808\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.0617 - acc: 0.9793\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.0540 - acc: 0.9819\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 184s 4ms/step - loss: 0.0462 - acc: 0.9843\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0441 - acc: 0.9850\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 185s 4ms/step - loss: 0.0429 - acc: 0.9856\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 193s 4ms/step - loss: 0.0488 - acc: 0.9835\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 194s 4ms/step - loss: 0.0527 - acc: 0.9828\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0501 - acc: 0.9827\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0310 - acc: 0.9899\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.0391 - acc: 0.9878\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.0415 - acc: 0.9866\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 189s 4ms/step - loss: 0.0379 - acc: 0.9874\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0351 - acc: 0.9887\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 185s 4ms/step - loss: 0.0395 - acc: 0.9870\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 184s 4ms/step - loss: 0.0427 - acc: 0.9872\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 179s 4ms/step - loss: 0.0268 - acc: 0.9909\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 185s 4ms/step - loss: 0.0255 - acc: 0.9919\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.0269 - acc: 0.9915\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0418 - acc: 0.9865\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.0312 - acc: 0.9899\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0289 - acc: 0.9910\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 185s 4ms/step - loss: 0.0276 - acc: 0.9912\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 179s 4ms/step - loss: 0.0317 - acc: 0.9899\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 180s 4ms/step - loss: 0.0317 - acc: 0.9895\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 179s 4ms/step - loss: 0.0249 - acc: 0.9923\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0220 - acc: 0.9931\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0291 - acc: 0.9914\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0288 - acc: 0.9909\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0277 - acc: 0.9909\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0264 - acc: 0.9917\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0226 - acc: 0.9929\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 206s 4ms/step - loss: 0.0295 - acc: 0.9907\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.0212 - acc: 0.9929\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 224s 4ms/step - loss: 0.0215 - acc: 0.9931\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0220 - acc: 0.9929\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 195s 4ms/step - loss: 0.0248 - acc: 0.9924\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 215s 4ms/step - loss: 0.0216 - acc: 0.9930\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 247s 5ms/step - loss: 0.0229 - acc: 0.9928\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.0247 - acc: 0.9921\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0209 - acc: 0.9932\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 179s 4ms/step - loss: 0.0192 - acc: 0.9936\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 179s 4ms/step - loss: 0.0188 - acc: 0.9943\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 178s 4ms/step - loss: 0.0198 - acc: 0.9937\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0199 - acc: 0.9937\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0233 - acc: 0.9922\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0202 - acc: 0.9937\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0158 - acc: 0.9951\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0176 - acc: 0.9950\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0165 - acc: 0.9945\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0211 - acc: 0.9933\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0180 - acc: 0.9945\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0199 - acc: 0.9937\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0192 - acc: 0.9940\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 178s 4ms/step - loss: 0.0121 - acc: 0.9964\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0157 - acc: 0.9952\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0234 - acc: 0.9932\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0177 - acc: 0.9947\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0168 - acc: 0.9949\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0152 - acc: 0.9953\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0164 - acc: 0.9951\n",
            "Epoch 80/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0159 - acc: 0.9948\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 173s 3ms/step - loss: 0.0174 - acc: 0.9949\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0115 - acc: 0.9967\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0143 - acc: 0.9957\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0163 - acc: 0.9950\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0153 - acc: 0.9953\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0129 - acc: 0.9956\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0156 - acc: 0.9955\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0134 - acc: 0.9960\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0183 - acc: 0.9945\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0136 - acc: 0.9956\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0106 - acc: 0.9965\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0120 - acc: 0.9961\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 177s 4ms/step - loss: 0.0180 - acc: 0.9946\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0164 - acc: 0.9951\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 175s 3ms/step - loss: 0.0209 - acc: 0.9942\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0106 - acc: 0.9968\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0122 - acc: 0.9963\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0153 - acc: 0.9956\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0139 - acc: 0.9957\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 178s 4ms/step - loss: 0.0128 - acc: 0.9961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x126226550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhCJCNflM3Kp",
        "colab_type": "text"
      },
      "source": [
        "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
        "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
        "## 維度如下方示範"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddebSspsM3Kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a43ba253-362f-4f7a-e727-ede3e29491b5"
      },
      "source": [
        "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
        "classifier.predict(input_example)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.9759049e-16, 2.6483683e-34, 1.4361813e-16, 9.8571396e-01,\n",
              "        1.4286015e-02, 0.0000000e+00, 4.3379846e-25, 2.8237597e-18,\n",
              "        5.6499127e-22, 0.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9IklTq2M3Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50b96d90-b83a-4c6c-96f1-d4fa6107b460"
      },
      "source": [
        "classifier.evaluate(x_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 15s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.6415183782577514, 0.6546]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}